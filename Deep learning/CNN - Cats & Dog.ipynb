{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd56762d-ddac-47bb-a7df-71be8bd65d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be0ab4e-f86f-4b96-82df-fa8fc82c0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51379a23-723c-4699-918b-1892620fb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d2a526-73b5-4fcb-92c5-c7c0da4b13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8805b440-9e54-48cc-b2f1-90a46f4a9a80",
   "metadata": {},
   "source": [
    "Init The CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d265cd-93b0-485d-9536-a43f017360c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c4bf92-cb55-4ea1-9b2a-04737027bc04",
   "metadata": {},
   "source": [
    "Add Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9698d1d-9fcd-4c6f-a834-634464572a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = Conv2D(filters = 32, kernel_size = (3, 3), strides = (1,1),\n",
    "                    padding = \"valid\", activation = \"relu\", input_shape = (64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e599d79-a978-4959-a4b0-6c941370bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4187bc8-9198-4880-8f4c-afc82edf80a3",
   "metadata": {},
   "source": [
    "Add Max Pool Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b808104-5d25-4b4a-9890-6cf581b6b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer = MaxPooling2D(pool_size = (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15ce7e6-d93a-4cf9-8a89-87df04e805d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(pool_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557a556-885d-48cd-9dea-4a3175647ef8",
   "metadata": {},
   "source": [
    "Add Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "669a7b57-5a2e-4aad-80cd-3aa189c54beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_layer = Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7751d413-719b-4e39-8ab7-44a6e1fbd0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(flatten_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2416a0-da03-45bd-8a9c-5f1c997200ec",
   "metadata": {},
   "source": [
    "Add Hidden / FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1a34900-ef73-4915-bf0f-bd82f4b52053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#units -- no of neurons in hidden Layer\n",
    "#kernel - -- weights -- kernel_initializer -- strategy to init the weights\n",
    "#activation --- the activation funtion for this Layer\n",
    "\n",
    "fc_layer = Dense(units = 200, kernel_initializer = \"random_uniform\", activation = \"relu\", bias_initializer = \"random_uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14bb8218-146f-4e41-9499-96a9e5f50c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(fc_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775f5b5-43a6-4dc6-816a-65cb3922e653",
   "metadata": {},
   "source": [
    "Add Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "199fda07-82a3-48b2-90d8-d7de3d03620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_layer = Dense(units = 1, activation = \"sigmoid\", kernel_initializer = \"random_uniform\",  bias_initializer = \"random_uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f82b14c-0792-4f9d-8272-cd3b22712e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(op_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "652b2ac8-d3c3-4f92-9c51-135e14cebb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30752)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               6150600   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,151,697\n",
      "Trainable params: 6,151,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92739d4a-9842-481d-8c30-40674071736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17a526c8-83dc-4686-b739-85d338410f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(cnn_model, show_shapes = True, show_dtype = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf6ff3-d0fc-4b26-8b22-f879cda7fc9e",
   "metadata": {},
   "source": [
    "Compile The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "521bfaa2-5ebf-45ae-a3c4-19e3daed3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43818b3e-2377-4d2c-911c-426d905817d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_o = Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13d96899-8e02-4b1a-a563-b6d71a2418c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss = \"binary_crossentropy\", optimizer = adam_o, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aca10c-00d3-40ca-9036-cef488977b96",
   "metadata": {},
   "source": [
    "Image Data Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "879dcb78-a216-4ff3-83dd-4146e89eb246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0230758-8dbe-4a09-b154-db922cb4ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72697661-75de-4564-9e83-474e9e5bdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rotation_range = random.randint(0, 30), \n",
    "                               shear_range = random.randint(0, 1000)/100,\n",
    "                               zoom_range = [0, 3],\n",
    "                               horizontal_flip = True,\n",
    "                               vertical_flip = True,\n",
    "                               rescale = 1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cd2f922-90b7-42b2-b504-e5ade68954a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale = 1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0076021c-8dd5-4354-afcf-91e20eaf4d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#path\n",
    "X_train = train_gen.flow_from_directory(r\"dataset/training_set\", target_size = (64, 64), color_mode = 'rgb',\n",
    "                             class_mode = \"binary\", batch_size = 32, shuffle = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5706d8a9-b9c6-469f-a35b-8ce36b52a184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x25e65c04c70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca0b6eee-5913-49fd-ad82-99d36ccea26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "X_test = test_gen.flow_from_directory(r\"dataset/test_set\", target_size = (64, 64), color_mode = 'rgb',\n",
    "                             class_mode = \"binary\", batch_size = 32, shuffle = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "122af982-e626-4739-a8ca-83f05447d439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3496b979-8e52-4a8b-a520-e203ade4f2a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anaconda\\envs\\learning\\lib\\site-packages\\keras\\preprocessing\\image.py:156\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anaconda\\envs\\learning\\lib\\site-packages\\keras\\preprocessing\\image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anaconda\\envs\\learning\\lib\\site-packages\\keras\\preprocessing\\image.py:370\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    368\u001b[0m filepaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepaths\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(index_array):\n\u001b[1;32m--> 370\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimage_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepaths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m     x \u001b[38;5;241m=\u001b[39m image_utils\u001b[38;5;241m.\u001b[39mimg_to_array(img, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format)\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# Pillow images should be closed after `load_img`,\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# but not PIL images.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anaconda\\envs\\learning\\lib\\site-packages\\keras\\utils\\image_utils.py:414\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    412\u001b[0m     color_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import PIL.Image. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m     )\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, io\u001b[38;5;241m.\u001b[39mBytesIO):\n\u001b[0;32m    418\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(path)\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "next(X_train)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fd8e6-1615-4e7e-a0d3-a39d7cbd78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3f6de-659b-4352-9999-dd22c0db99bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
